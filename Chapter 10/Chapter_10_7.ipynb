{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Dynamic model using Subclassing API"
      ],
      "metadata": {
        "id": "mlC0BrdxQC-t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6pOrtF_PX4l"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train.shape[1:]\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
        "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)"
      ],
      "metadata": {
        "id": "t_XZHrIxPwZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepModel(keras.Model):\n",
        "  def __init__(self, units=30, activation='relu', **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "    self.main_output = keras.layers.Dense(1)\n",
        "    self.aux_output = keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    input_A, input_B = inputs\n",
        "    hidden1 = self.hidden1(input_B)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    concat = keras.layers.Concatenate([input_A, hidden2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden2)\n",
        "    return main_output, aux_output\n",
        "\n",
        "model = WideAndDeepModel()\n"
      ],
      "metadata": {
        "id": "Zb_Vd596QGpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer=\"sgd\")model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "YM3Ec-uESD7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
      ],
      "metadata": {
        "id": "iN0NMNr8SEeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "A4d5mXj3SHae",
        "outputId": "b0bf935b-9a74-4987-f99e-46c58936edca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "358/363 [============================>.] - ETA: 0s"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a1e9d8b43f5c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mX_train_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0;34m\"Unexpected result of `train_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                         \u001b[0;34m\"(Empty logs). This could be due to issues in input \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss, main_loss, _aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
        "print(total_loss, main_loss, _aux_loss)"
      ],
      "metadata": {
        "id": "D82BaxDBSJp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_max = model.predict([X_new_A, X_new_B])\n",
        "print(y_pred_main, y_pred_max)"
      ],
      "metadata": {
        "id": "WOGfgNxWSLcN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}