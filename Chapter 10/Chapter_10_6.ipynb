{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Auxilary Output\n",
        "You may want to add some auxiliary outputs in a NN architecture to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network.(regularization technique)"
      ],
      "metadata": {
        "id": "abaRXeAnJ-My"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WXcHnD-cJ5cs"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train.shape[1:]\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
        "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)"
      ],
      "metadata": {
        "id": "dKbWjlfbKMKf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ],
      "metadata": {
        "id": "UoyaRI1NKml-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "j2_We6hyKvUp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
      ],
      "metadata": {
        "id": "GzMU6u21LMa9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38cdAj7LBs-",
        "outputId": "01359885-b4c6-48d8-f222-abbd864b4fae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 3s 4ms/step - loss: 0.9420 - main_output_loss: 0.7983 - aux_output_loss: 2.2359 - val_loss: 0.6771 - val_main_output_loss: 0.6221 - val_aux_output_loss: 1.1725\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5907 - main_output_loss: 0.5392 - aux_output_loss: 1.0542 - val_loss: 0.5877 - val_main_output_loss: 0.5428 - val_aux_output_loss: 0.9916\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 1.2652 - main_output_loss: 1.2574 - aux_output_loss: 1.3355 - val_loss: 0.5625 - val_main_output_loss: 0.5243 - val_aux_output_loss: 0.9066\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5429 - main_output_loss: 0.5073 - aux_output_loss: 0.8625 - val_loss: 0.5056 - val_main_output_loss: 0.4725 - val_aux_output_loss: 0.8038\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.5028 - main_output_loss: 0.4732 - aux_output_loss: 0.7690 - val_loss: 0.4862 - val_main_output_loss: 0.4576 - val_aux_output_loss: 0.7435\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4879 - main_output_loss: 0.4621 - aux_output_loss: 0.7198 - val_loss: 0.4716 - val_main_output_loss: 0.4449 - val_aux_output_loss: 0.7116\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4736 - main_output_loss: 0.4492 - aux_output_loss: 0.6939 - val_loss: 0.4655 - val_main_output_loss: 0.4416 - val_aux_output_loss: 0.6800\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4621 - main_output_loss: 0.4393 - aux_output_loss: 0.6670 - val_loss: 0.4516 - val_main_output_loss: 0.4282 - val_aux_output_loss: 0.6623\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4536 - main_output_loss: 0.4313 - aux_output_loss: 0.6544 - val_loss: 0.4418 - val_main_output_loss: 0.4195 - val_aux_output_loss: 0.6424\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4471 - main_output_loss: 0.4257 - aux_output_loss: 0.6394 - val_loss: 0.4428 - val_main_output_loss: 0.4216 - val_aux_output_loss: 0.6335\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4434 - main_output_loss: 0.4230 - aux_output_loss: 0.6264 - val_loss: 0.4371 - val_main_output_loss: 0.4164 - val_aux_output_loss: 0.6231\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4369 - main_output_loss: 0.4171 - aux_output_loss: 0.6151 - val_loss: 0.4248 - val_main_output_loss: 0.4047 - val_aux_output_loss: 0.6054\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4406 - main_output_loss: 0.4219 - aux_output_loss: 0.6089 - val_loss: 0.4215 - val_main_output_loss: 0.4018 - val_aux_output_loss: 0.5986\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4285 - main_output_loss: 0.4096 - aux_output_loss: 0.5988 - val_loss: 0.4095 - val_main_output_loss: 0.3901 - val_aux_output_loss: 0.5834\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4220 - main_output_loss: 0.4039 - aux_output_loss: 0.5849 - val_loss: 0.4106 - val_main_output_loss: 0.3922 - val_aux_output_loss: 0.5770\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4155 - main_output_loss: 0.3977 - aux_output_loss: 0.5755 - val_loss: 0.4066 - val_main_output_loss: 0.3889 - val_aux_output_loss: 0.5661\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4103 - main_output_loss: 0.3930 - aux_output_loss: 0.5666 - val_loss: 0.3981 - val_main_output_loss: 0.3802 - val_aux_output_loss: 0.5598\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4032 - main_output_loss: 0.3862 - aux_output_loss: 0.5566 - val_loss: 0.3946 - val_main_output_loss: 0.3772 - val_aux_output_loss: 0.5510\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4042 - main_output_loss: 0.3875 - aux_output_loss: 0.5546 - val_loss: 0.3943 - val_main_output_loss: 0.3778 - val_aux_output_loss: 0.5430\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4079 - main_output_loss: 0.3929 - aux_output_loss: 0.5434 - val_loss: 0.3914 - val_main_output_loss: 0.3756 - val_aux_output_loss: 0.5339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss, main_loss, _aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
        "print(total_loss, main_loss, _aux_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O9EUbs3LjIR",
        "outputId": "07bb1173-0ca8-4ccb-dd2f-d4341310b033"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 0.3786 - main_output_loss: 0.3617 - aux_output_loss: 0.5315\n",
            "0.37864241003990173 0.36165574193000793 0.5315234065055847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_max = model.predict([X_new_A, X_new_B])\n",
        "print(y_pred_main, y_pred_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBWbqNm0L52X",
        "outputId": "bc110484-9fbd-4094-f2a5-b555817bea65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 617ms/step\n",
            "[[1.0947163]\n",
            " [1.8038183]\n",
            " [1.1701789]] [[1.0655814]\n",
            " [1.8611231]\n",
            " [1.0172672]]\n"
          ]
        }
      ]
    }
  ]
}